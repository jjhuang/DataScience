{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline  \n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import skflow\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import datasets, cross_validation, metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "for col in ['DayOfWeek','PdDistrict']:\n",
    "    dummies = pd.get_dummies(data[col])\n",
    "    data[col[0:3]+\"_\"+dummies.columns] = dummies\n",
    "\n",
    "cat_dict = {}\n",
    "for col in ['Category','DayOfWeek','PdDistrict']:\n",
    "    s = pd.Series(data[col], dtype=\"category\")\n",
    "    cat_dict[col] = s.cat.categories\n",
    "    s.cat.categories = [int(num) for num in range(0,len(s.cat.categories))]\n",
    "    data[col[0:3]+'Num'] = pd.Series(s, dtype=\"int\")\n",
    "\n",
    "data[['X','Y']] = preprocessing.normalize(data[['X','Y']], norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['Category'] = pd.Series(data['Category'], dtype=\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "y = data['CatNum']\n",
    "# X = data[[cat for cat in data.columns if 'Day_' in cat or 'PdD_' in cat]+['X','Y']]\n",
    "# X = data[['X','Y']]\n",
    "X = data[['X','Y','DayNum','PdDNum']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dnn_relu(X,y):\n",
    "    layers = skflow.ops.dnn(X, [500,500,500], tf.nn.relu)\n",
    "    return skflow.models.logistic_regression(layers, y)\n",
    "\n",
    "def exp_decay(global_step):\n",
    "    return tf.train.exponential_decay(global_step,\n",
    "                                      learning_rate=0.1,                                      \n",
    "                                      decay_steps=2,\n",
    "                                      decay_rate=0.001)\n",
    "\n",
    "def run_NN(X_train, y_train, X_test, y_test, steps=500, learn_rate=1e-2):\n",
    "    classifier = skflow.TensorFlowEstimator(model_fn=dnn_relu,\n",
    "                                            n_classes=39,\n",
    "                                            batch_size=128,\n",
    "                                            learning_rate=learn_rate,\n",
    "                                            steps=steps)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #1, avg. loss: 4.69659\n",
      "Step #1001, avg. loss: 2.74758\n",
      "Step #2001, avg. loss: 2.67331\n",
      "Step #3001, avg. loss: 2.66698\n",
      "Step #4001, avg. loss: 2.66476\n",
      "Step #5001, avg. loss: 2.65872\n",
      "Step #6001, epoch #1, avg. loss: 2.65889\n",
      "Step #7001, epoch #1, avg. loss: 2.65911\n",
      "Step #8001, epoch #1, avg. loss: 2.64910\n",
      "Step #9001, epoch #1, avg. loss: 2.64756\n",
      "Training: 0.210849625377\n",
      "Training: 0.21129206765\n"
     ]
    }
   ],
   "source": [
    "classifier = run_NN(X_train, y_train, X_test, y_test, steps=10000, learn_rate=1e-2)\n",
    "pred_train = classifier.predict(X_train)\n",
    "pred_test = classifier.predict(X_test)\n",
    "print \"Training:\", metrics.accuracy_score(pred_train, y_train)\n",
    "print \"Testing:\", metrics.accuracy_score(pred_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_test_labels = [cat_dict['Category'][p] for p in pred_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "predict = svc(X_test)\n",
    "\n",
    "print \"Training:\", metrics.accuracy_score(pred_train, y_train)\n",
    "print \"Testing:\", metrics.accuracy_score(pred_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
